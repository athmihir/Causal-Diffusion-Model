{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b637e27",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264d236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asardesai/Projects/Causal-Diffusion-Model/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-18 15:53:36 - INFO - DEBUG\n"
     ]
    }
   ],
   "source": [
    "from barmnist import BarMNIST\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from cdm.utils import visualize_image\n",
    "import os\n",
    "from diffusers import UNet2DModel, DDPMScheduler\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from cdm.scm import EdgeType, Vertex, Edge, SCM\n",
    "\n",
    "# Setup the logger\n",
    "load_dotenv()\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"celeba.log\"),  # Log to file\n",
    "        logging.StreamHandler()          # Log to console\n",
    "    ],\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "logger.setLevel(os.getenv('LOG_LEVEL'))\n",
    "logger.info(os.getenv('LOG_LEVEL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6153c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = int(os.getenv('BATCH_SIZE'))\n",
    "NUM_EPOCHS = int(os.getenv('NUM_EPOCHS'))\n",
    "MODEL_PATH = 'mnist_model.pt'\n",
    "DEVICE_NAME = os.getenv('DEVICE')\n",
    "DEVICE = torch.device(DEVICE_NAME) if torch.cuda.is_available() else 'cpu'\n",
    "IMAGE_RESOLUTION = 32 # Dimensions of image to be passed into VAE\n",
    "IMAGE_CHANNELS = 3 # RGB\n",
    "LATENT_SPACE_RESOLUTION = int(IMAGE_RESOLUTION / 8) # Size of the latent space\n",
    "LATENT_SPACE_CHANNELS = 4 # Channel dimension of latent space\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764ab36a",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a7cab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing BAR MNIST\n",
      "Causal Diagram:frontdoor\n",
      "BAR MNISTfrontdoor dataset already exists\n"
     ]
    }
   ],
   "source": [
    "cg = 'frontdoor'\n",
    "\n",
    "BarMNIST(cg=cg, ow=True)\n",
    "trans_f = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                ])\n",
    "train_set = BarMNIST(cg=cg, root='./', env='train', transform=trans_f)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8415cadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.])\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAcABwDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDw7+0v+mX/AI9/9aj+0v8Apl/49/8AWqjXUWtnoeg3sg1tXvv9HilhjiDKGLrk85GccfXnuMV69XinM6a/iNvsox/y8zkrOnSXwtvst3t/mYv9pf8ATL/x7/61H9pf9Mv/AB7/AOtXSTeKPDce/wCyeE4GLjO6aTofpg8cDoR39a5nVb2PUdTmu47ZLZZSD5UeNqnABxgDvz/j1qKPFWbzfvNxXmofojOg5VH79JxXm1+SbDSobKfUoYtRneC1YkPKgyV4OP1xXSeJvsMvh2xMerwahdW0rRh9zeYYm3MuQfTjPpnFcfRXh1KHPUjPmat0/rU1q4b2lWNTma5emluvz69woooroOo//9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABRElEQVR4AeWTLUuEQRDHf+NLECxGmzbRYjJ6QZOaVDCJn8ADwaZgEItVg8liE8FPcAhWwegHsBxYDzT4Ojs+Cw+y87D3cIKHw7K7zMz+5z8vKyKf9FoGeg0Y8PoHdOg3yPZP+n+c6RKMFvOpjcqT75RWoWH+e3Bkl3W4gClQ0A6MmVJyZFmkJfIu8lq5HxRYeTWdg3k/oSdowhnsFD4B23VvwwbcwgdcWuJXJd9DULiU+DU9gRFYM9BdmIHxFEBS55Z0wco36dorDH5NNWVd2twa4gY8FekY2S3XxTP4TLdh0chOdE/Vixb0gyI3RjYOYJVzyZZi2oJjq6bW9M7m5rk7sgH/54u3qJiFa3iBR1iJypyzxDpez0Xa8Tvqv9SlHWtEa+aZiK2TdA/78ADTsAnDCS9PFeJ6ttr6VKNqg8WH/xz0C9UqPDyl5vAdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample = None\n",
    "for idx, (x, y) in enumerate(train_loader):\n",
    "    x_sample = x[0]\n",
    "    print(y[0])\n",
    "    break\n",
    "\n",
    "visualize_image(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aca39ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 15:56:45 - INFO - Initializing a new model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet2DModel(\n",
       "  (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): AttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Attention(\n",
       "          (group_norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): AttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Attention(\n",
       "          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): AttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Attention(\n",
       "          (group_norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-2): 3 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): AttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Attention(\n",
       "          (group_norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 768, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): AttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Attention(\n",
       "          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 768, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): AttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Attention(\n",
       "          (group_norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1-2): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlock2D(\n",
       "    (attentions): ModuleList(\n",
       "      (0): Attention(\n",
       "        (group_norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (to_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (to_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (to_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (to_out): ModuleList(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-1): 2 x ResnetBlock2D(\n",
       "        (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (time_emb_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_norm_out): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "  (conv_act): SiLU()\n",
       "  (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network or load an existing one\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    net = torch.load(MODEL_PATH, weights_only=False, map_location=DEVICE)\n",
    "    logger.info(\"Loading model from checkpoint...\")\n",
    "else:\n",
    "    net = UNet2DModel(\n",
    "        sample_size=IMAGE_RESOLUTION,  # the target image resolution\n",
    "        in_channels=IMAGE_CHANNELS,  # the number of input channels, 3 for RGB images\n",
    "        out_channels=IMAGE_CHANNELS,  # the number of output channels\n",
    "        layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "        block_out_channels=(128, 256, 512, 512),  # Roughly matching our basic unet example\n",
    "        down_block_types=(\n",
    "            \"AttnDownBlock2D\",  # a regular ResNet downsampling block\n",
    "            \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "            \"AttnDownBlock2D\",\n",
    "            \"DownBlock2D\"\n",
    "        ),\n",
    "        up_block_types=(\n",
    "            \"UpBlock2D\",\n",
    "            \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "            \"AttnUpBlock2D\",  # a regular ResNet upsampling block\n",
    "            \"AttnUpBlock2D\",  # a regular ResNet upsampling block\n",
    "        ),\n",
    "    )  # <<<\n",
    "    logger.info(\"Initializing a new model...\")\n",
    "net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e144d4e9",
   "metadata": {},
   "source": [
    "### Initialize the SCM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da210bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vertex = Vertex('Digit', (BATCH_SIZE, 10))\n",
    "c_vertex = Vertex('Color', (BATCH_SIZE, 2))\n",
    "b_vertex = Vertex('Bar', (BATCH_SIZE, 2))\n",
    "edge_list = [\n",
    "    Edge(d_vertex, c_vertex, EdgeType.DIRECTED),\n",
    "    Edge(c_vertex, b_vertex, EdgeType.DIRECTED),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974be228",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
